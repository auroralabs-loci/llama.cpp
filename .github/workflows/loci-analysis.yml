name: LOCI Analysis
on:
  workflow_dispatch:
  pull_request:
    types: [opened, synchronize, reopened]
  push:
    branches: [ main ]

env:
  LOCI_PROJECT: Llama CPP
  LOCI_API_KEY: '${{ secrets.LOCI_API_KEY }}'
  LOCI_BACKEND_URL: '${{ vars.LOCI_BACKEND_URL }}'

jobs:
  build-and-upload:
    name: Build and Upload Artifacts
    runs-on: ubuntu-latest
    environment: ${{ vars.LOCI_ENV || 'PROD__AL_DEMO' }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install dependencies (including curl)
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            cmake \
            build-essential \
            gcc-aarch64-linux-gnu \
            g++-aarch64-linux-gnu \
            libcurl4-openssl-dev
     
      - name: Create build directory and configure with CMake
        run: |
          mkdir build
          cd build
          cmake .. \
            -DCMAKE_SYSTEM_NAME=Linux \
            -DCMAKE_SYSTEM_PROCESSOR=aarch64 \
            -DCMAKE_C_COMPILER=aarch64-linux-gnu-gcc \
            -DCMAKE_CXX_COMPILER=aarch64-linux-gnu-g++ \
            -DCMAKE_OSX_SYSROOT= \
            -DCMAKE_OSX_DEPLOYMENT_TARGET= \
            -DBUILD_SHARED_LIBS=ON \
            -DLLAMA_BUILD_TESTS=OFF \
            -DLLAMA_BUILD_EXAMPLES=OFF \
            -DLLAMA_BUILD_SERVER=ON \
            -DLLAMA_BUILD_COMMON=ON \
            -DLLAMA_BUILD_TOOLS=ON \
            -DLLAMA_CURL=OFF \
            -DCMAKE_BUILD_TYPE=Debug \
            -DCMAKE_C_FLAGS="-march=armv8-a -Wl,-Bsymbolic" \
            -DCMAKE_CXX_FLAGS="-march=armv8-a -Wl,-Bsymbolic"


      - name: Build project
        run: |
          cd build
          cmake --build . -j4

      - name: Upload build artifacts
        uses: auroralabs-loci/loci-action@v1
        with:
          mode: upload
          binaries: |
                build/bin/libggml.so*
                build/bin/libllama.so*
                build/bin/libggml-cpu.so*
                build/bin/libggml-base.so*
                build/bin/libmtmd.so*
                build/bin/llama-bench
                build/bin/llama-cvector-generator
                build/bin/llama-gemma3-cli
                build/bin/llama-gguf-split
                build/bin/llama-llava-cli
                build/bin/llama-minicpmv-cli
                build/bin/llama-quantize
                build/bin/llama-qwen2vl-cli
                build/bin/llama-run
                build/bin/llama-tokenize
                build/bin/llama-tts
          project:  ${{ env.LOCI_PROJECT }}
          wait-base: 'true'