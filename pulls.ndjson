{"pull_number":"18755","title":"Kimi-Linear support (backend agnostic + MLA KV cache)","body":"@CISC \r\n\r\nI have implemented a backend agnostic Kimi-Linear support with MLA KV cache support. I also followed CISC's comments to minimize changes and putting code in the right place.\r\n\r\nThis file only committed 18 files compare to 51 files in the cacaview PR. \r\nhttps://github.com/ggml-org/llama.cpp/pull/17592\r\nI believe it should be quite easy to review and merge. I created this PR such that it is easier for reviewers' to review.\r\n\r\nIt is also sync'd to b7738. So it is ready to merge any time.\r\n\r\nPlease let me know what else I need to do. Thanks a lot in advance.","pull_head_sha":"2a62df613f3d51de7d4913161accae3630163478","loci_pr_branch":"loci/pr-18755-Kimi-Linear","short_merge_base":"b0311c1","loci_main_branch":"loci/main-b0311c1"}
