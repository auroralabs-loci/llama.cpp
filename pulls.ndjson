{"pull_number":"19547","title":"Add Nemotron Nano 12B v2 VL support","body":"Adding support for [Nemotron-Nano-12B-v2-VL](https://huggingface.co/nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL-BF16).\r\n\r\nThis model uses:\r\n- **LLM**: NemotronH (hybrid Mamba2/Attention/MLP architecture)\r\n- **Vision Encoder**: RADIOv2.5-H (ViT)\r\n- **Projector**: RMSNorm + MLP with SquaredReLU activation\r\n\r\n## Instructions:\r\n### GGUF Conversion:\r\n```bash\r\npython convert_hf_to_gguf.py <path/to/model> --outfile nano_v2.gguf\r\npython convert_hf_to_gguf.py <path/to/model> --mmproj --outfile nano_v2_mmproj.gguf\r\n```\r\n\r\n### Quantization:\r\n```bash\r\nllama-quantize nano_v2.gguf nano_v2_q4_0.gguf Q4_0\r\n```\r\n\r\n### Inference:\r\n```bash\r\nllama-mtmd-cli -m nano_v2_q4_0.gguf --mmproj nano_v2_mmproj.gguf -p \"Describe these images\" --image image_1.jpg,image_2.jpg -c 4096 --jinja\r\n```\r\n\r\n### Note:\r\n- All testing done on Windows with CUDA backend.\r\n- AI tools were used in assistive capacity during development.\r\n\r\n@ngxson I would appreciate your review. Happy to make any updates as needed.","pull_head_sha":"a9f70e204897cbed4f040f449afabc4eb46f1a22","loci_pr_branch":"loci/pr-19547-nemo_nano_12b_v2_vl_support","short_merge_base":"4ae1b75","loci_main_branch":"loci/main-4ae1b75","use_loci_base":0}
