{"pull_number":"19270","title":"llama : add llama_memory_can_rm_suffix()","body":"fix #19267\r\n\r\nMemory modules that do not support removing the last tokens from the context (such as recurrent modules) cannot perform speculative decoding. Add new `llama_memory_can_rm_suffix()` to query this functionality and use it in `llama-server` to disable speculative decoding for those contexts.","pull_head_sha":"d30e59b62a15ef4266a6503e3f4eba770aec001b","loci_pr_branch":"loci/pr-19270-gg-spec-disable-for-recurrent","short_merge_base":"6fdddb4","loci_main_branch":"loci/main-6fdddb4"}
